{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8c8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import numpy\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import os\n",
    "allowed_roles = [\"python_developer\",\"cloud_architect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa57bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extracter(image):\n",
    "    #Function detects faces in provided image and returns the cropped grayscale image\n",
    "    #If no face is detected , it returns None\n",
    "    #Load Haarcascade Classifier\n",
    "    face_classifier = cv2.CascadeClassifier('./Haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face = face_classifier.detectMultiScale(image)\n",
    "    if len(face) == 0:\n",
    "        return None\n",
    "    #Crop face found in image\n",
    "    for (x,y,w,h) in face:\n",
    "        cropped_face = cv2.cvtColor(image[y:y+h,x:x+w],cv2.COLOR_BGR2GRAY)\n",
    "        return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28ef52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_collect(user_role,user_name):\n",
    "    #Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    #count 100 samples of your faces from webcam input\n",
    "    while True:\n",
    "        return_value , frame = cap.read()\n",
    "        if face_extracter(frame) is not None:\n",
    "            count +=1\n",
    "            face = cv2.resize(face_extracter(frame),(300,300))\n",
    "            file_name_path = \"./Images_Dataset/\"+user_role+\"/\"+user_name + \"/\" + str(count) + \".jpg\"\n",
    "            cv2.imwrite(file_name_path,face)\n",
    "            print(\"Face detected:\",count)\n",
    "            #Put count on images and display live count\n",
    "            cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,0),2)\n",
    "            cv2.imshow(\"Face Dataset Collection\",face)\n",
    "        else:\n",
    "            print(\"face not found\")\n",
    "            pass\n",
    "        if cv2.waitKey(1) == 13 or count == 100:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Collecting samples complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c48db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(user_role,user_name):\n",
    "    data_path = \"./Images_Dataset/\"+ user_role + \"/\" + user_name + \"/\"\n",
    "    imagefiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "    #Create array for training data and labels\n",
    "    Training_data , Labels = [],[]\n",
    "    #Open Training images in our datapath\n",
    "    #Create numpy array for training data\n",
    "    for i,files in enumerate(imagefiles):\n",
    "        image_path = data_path + imagefiles[i]\n",
    "        image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        Training_data.append(np.asarray(image))\n",
    "        Labels.append(np.asarray(i))\n",
    "    return Training_data,Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0dd9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(Training_data,Labels,user_role,user_name,model_location):\n",
    "    #Initialize Facial Recognization\n",
    "    #model = cv2.face.createLBPHFaceRecognizer()\n",
    "    #NOTE: For opencv 3.0 use cv2.face.createLBPHFaceRecognizer\n",
    "    #pip install opencv-contrib-python\n",
    "    model_name= user_role + \"_\" + user_name\n",
    "    model_location = model_location + user_role + \"/\" + model_name + \".h5\"\n",
    "    model_name = cv2.face_LBPHFaceRecognizer.create()\n",
    "    model_name.train(np.asarray(Training_data),np.asarray(Labels))\n",
    "    model_name.save(model_location)\n",
    "    print(\"Model Trained Successfully\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b518374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Press 1:For Creating New User\n",
      "Press 2:For Existing Users\n",
      "Press 3:For Adding New Roles\n",
      "\n",
      "Enter your choice:1\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Press 1:For Creating New User\n",
    "Press 2:For Existing Users\n",
    "Press 3:For Adding New Roles\n",
    "\"\"\")\n",
    "user_input = int(input(\"Enter your choice:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fc4836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLOWED_ROLES:  python_developer cloud_architect Enter role for this user:python_developer\n",
      "\n",
      "Enter Unique Name for this user:shubham\n",
      "Creating shubham User for python_developer role\n",
      "Please Wait...\n",
      "\n",
      "        Collecting Dataset...\n",
      "        Please stand in front of camera in well-lit environment..\n",
      "        \n",
      "Do you agree[y]/N:y\n",
      "Collecting Dataset Images...\n",
      "Face detected: 1\n",
      "Face detected: 2\n",
      "Face detected: 3\n",
      "Face detected: 4\n",
      "Face detected: 5\n",
      "Face detected: 6\n",
      "Face detected: 7\n",
      "Face detected: 8\n",
      "face not found\n",
      "Face detected: 9\n",
      "Face detected: 10\n",
      "Face detected: 11\n",
      "Face detected: 12\n",
      "Face detected: 13\n",
      "Face detected: 14\n",
      "Face detected: 15\n",
      "Face detected: 16\n",
      "Face detected: 17\n",
      "Face detected: 18\n",
      "Face detected: 19\n",
      "Face detected: 20\n",
      "Face detected: 21\n",
      "Face detected: 22\n",
      "face not found\n",
      "Face detected: 23\n",
      "Face detected: 24\n",
      "Face detected: 25\n",
      "Face detected: 26\n",
      "Face detected: 27\n",
      "Face detected: 28\n",
      "Face detected: 29\n",
      "Face detected: 30\n",
      "Face detected: 31\n",
      "Face detected: 32\n",
      "Face detected: 33\n",
      "Face detected: 34\n",
      "Face detected: 35\n",
      "Face detected: 36\n",
      "Face detected: 37\n",
      "Face detected: 38\n",
      "Face detected: 39\n",
      "Face detected: 40\n",
      "Face detected: 41\n",
      "Face detected: 42\n",
      "Face detected: 43\n",
      "Face detected: 44\n",
      "Face detected: 45\n",
      "Face detected: 46\n",
      "Face detected: 47\n",
      "Face detected: 48\n",
      "Face detected: 49\n",
      "Face detected: 50\n",
      "Face detected: 51\n",
      "face not found\n",
      "Face detected: 52\n",
      "Face detected: 53\n",
      "Face detected: 54\n",
      "Face detected: 55\n",
      "Face detected: 56\n",
      "Face detected: 57\n",
      "face not found\n",
      "Face detected: 58\n",
      "face not found\n",
      "Face detected: 59\n",
      "Face detected: 60\n",
      "Face detected: 61\n",
      "face not found\n",
      "face not found\n",
      "Face detected: 62\n",
      "Face detected: 63\n",
      "face not found\n",
      "Face detected: 64\n",
      "face not found\n",
      "Face detected: 65\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "Face detected: 66\n",
      "face not found\n",
      "Face detected: 67\n",
      "face not found\n",
      "Face detected: 68\n",
      "Face detected: 69\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "Face detected: 70\n",
      "Face detected: 71\n",
      "face not found\n",
      "Face detected: 72\n",
      "face not found\n",
      "Face detected: 73\n",
      "Face detected: 74\n",
      "Face detected: 75\n",
      "Face detected: 76\n",
      "Face detected: 77\n",
      "Face detected: 78\n",
      "Face detected: 79\n",
      "Face detected: 80\n",
      "Face detected: 81\n",
      "Face detected: 82\n",
      "Face detected: 83\n",
      "Face detected: 84\n",
      "Face detected: 85\n",
      "Face detected: 86\n",
      "Face detected: 87\n",
      "Face detected: 88\n",
      "face not found\n",
      "Face detected: 89\n",
      "face not found\n",
      "face not found\n",
      "Face detected: 90\n",
      "Face detected: 91\n",
      "Face detected: 92\n",
      "Face detected: 93\n",
      "Face detected: 94\n",
      "Face detected: 95\n",
      "Face detected: 96\n",
      "Face detected: 97\n",
      "Face detected: 98\n",
      "Face detected: 99\n",
      "Face detected: 100\n",
      "Collecting samples complete\n",
      "Finally Dataset Collected\n",
      "Transforming Dataset Images..\n",
      "Please Wait..\n",
      "Model Trained Successfully\n"
     ]
    }
   ],
   "source": [
    "if user_input == 1:\n",
    "    print(\"ALLOWED_ROLES:  \",end=\"\")\n",
    "    for role in allowed_roles:\n",
    "        print(role,end=\" \")\n",
    "    user_role = input(\"Enter role for this user:\")\n",
    "    if user_role in allowed_roles:\n",
    "        user_name = input(\"\\nEnter Unique Name for this user:\")\n",
    "        print(\"Creating {0} User for {1} role\\nPlease Wait...\".format(user_name,user_role))\n",
    "        print(\"\"\"\n",
    "        Collecting Dataset...\n",
    "        Please stand in front of camera in well-lit environment..\n",
    "        \"\"\")\n",
    "        agree = input(\"Do you agree[y]/N:\")\n",
    "        if agree == 'y':\n",
    "            dataset_folder_name= \"./Images_Dataset/\"+user_role+\"/\"+user_name+\"/\"\n",
    "            os.mkdir(dataset_folder_name)\n",
    "            print(\"Collecting Dataset Images...\")\n",
    "            dataset_collect(user_role=user_role,user_name=user_name)\n",
    "            print(\"Finally Dataset Collected\")\n",
    "            print(\"Transforming Dataset Images..\\nPlease Wait..\")\n",
    "            Training_data,Labels = transform_dataset(user_role=user_role,user_name=user_name)\n",
    "            training_model(Training_data,Labels,user_role,user_name,\"./Models/\")\n",
    "        elif agree == \"N\":\n",
    "            print(\"ABORTED........\")\n",
    "        else:\n",
    "            print(\"Incorrect value passed\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0e6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca827ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e08f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d924ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadd18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0420dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f90ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb04494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4d070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27f988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8ba4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297e5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ff8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6fe80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3cb5c0a",
   "metadata": {},
   "source": [
    "#### Collecting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Load Haarcascade Classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extracter(img):\n",
    "    #Function detects faces and returns the cropped images\n",
    "    #If no faces detected , it returns Input Image\n",
    "    #gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    \n",
    "    #Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "#Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "#count 100 samples of your faces from webcam input\n",
    "\n",
    "while True:\n",
    "    return_value , frame = cap.read()\n",
    "    if face_extracter(frame) is not None:\n",
    "        count +=1\n",
    "        face = cv2.resize(cv2.cvtColor(face_extracter(frame),cv2.COLOR_BGR2GRAY),(400,400))\n",
    "        file_name_path = \"./faces/user/\" + str(count) + \".jpg\"\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        print(\"Face detected:\",count)\n",
    "        #Put count on images and display live count\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,0),2)\n",
    "        cv2.imshow(\"Face Dataset Collection\",face)\n",
    "    else:\n",
    "        print(\"face not found\")\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13 or count == 100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Collecting samples complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd5eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74df90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76a799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb83307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "data_path = \"./faces/user/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "#Create array for training data and labels\n",
    "Training_data , Labels = [],[]\n",
    "#Open Training images in our datapath\n",
    "#Create numpy array for training data\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    Training_data.append(np.asarray(image))\n",
    "    Labels.append(np.asarray(i))\n",
    "#Initialize Facial Recognization\n",
    "#model = cv2.face.createLBPHFaceRecognizer()\n",
    "#NOTE: For opencv 3.0 use cv2.face.createLBPHFaceRecognizer\n",
    "#pip install opencv-contrib-python\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\n",
    "model.train(np.asarray(Training_data),np.asarray(Labels))\n",
    "print(\"Model Trained Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057369ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_detector(img,size=0.5):\n",
    "    #Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if len(faces) == 0:\n",
    "        return img,[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    return_value,frame = cap.read()\n",
    "    image,face = face_detector(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        if results[1]<500:\n",
    "            confidence = int(100*(1-(results[1]/400)))\n",
    "            display_string = str(confidence) + \"% confidence it is user\"\n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,150),2)\n",
    "        if confidence > 90:\n",
    "            cv2.putText(image,\"hello\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow(\"Face Reognization\",image)\n",
    "        else:\n",
    "            cv2.putText(img,\"Not Found\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),1)\n",
    "            cv2.imshow(\"face Recognization\",image)\n",
    "    except:\n",
    "        cv2.putText(image,\"No Face Found\",(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,\"Locked\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow(\"Face Recognization\",image)\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808d1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
