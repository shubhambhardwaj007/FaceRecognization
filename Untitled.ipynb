{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cb5c0a",
   "metadata": {},
   "source": [
    "#### Collecting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486fad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected: 1\n",
      "Face detected: 2\n",
      "Face detected: 3\n",
      "Face detected: 4\n",
      "Face detected: 5\n",
      "Face detected: 6\n",
      "Face detected: 7\n",
      "Face detected: 8\n",
      "Face detected: 9\n",
      "Face detected: 10\n",
      "Face detected: 11\n",
      "Face detected: 12\n",
      "Face detected: 13\n",
      "Face detected: 14\n",
      "Face detected: 15\n",
      "Face detected: 16\n",
      "Face detected: 17\n",
      "Face detected: 18\n",
      "Face detected: 19\n",
      "Face detected: 20\n",
      "Face detected: 21\n",
      "Face detected: 22\n",
      "Face detected: 23\n",
      "Face detected: 24\n",
      "Face detected: 25\n",
      "Face detected: 26\n",
      "Face detected: 27\n",
      "Face detected: 28\n",
      "Face detected: 29\n",
      "Face detected: 30\n",
      "Face detected: 31\n",
      "Face detected: 32\n",
      "Face detected: 33\n",
      "Face detected: 34\n",
      "Face detected: 35\n",
      "Face detected: 36\n",
      "Face detected: 37\n",
      "Face detected: 38\n",
      "Face detected: 39\n",
      "Face detected: 40\n",
      "Face detected: 41\n",
      "Face detected: 42\n",
      "Face detected: 43\n",
      "Face detected: 44\n",
      "Face detected: 45\n",
      "Face detected: 46\n",
      "Face detected: 47\n",
      "Face detected: 48\n",
      "Face detected: 49\n",
      "Face detected: 50\n",
      "Face detected: 51\n",
      "Face detected: 52\n",
      "Face detected: 53\n",
      "Face detected: 54\n",
      "Face detected: 55\n",
      "Face detected: 56\n",
      "Face detected: 57\n",
      "Face detected: 58\n",
      "Face detected: 59\n",
      "Face detected: 60\n",
      "Face detected: 61\n",
      "Face detected: 62\n",
      "Face detected: 63\n",
      "Face detected: 64\n",
      "Face detected: 65\n",
      "Face detected: 66\n",
      "Face detected: 67\n",
      "Face detected: 68\n",
      "Face detected: 69\n",
      "Face detected: 70\n",
      "Face detected: 71\n",
      "Face detected: 72\n",
      "Face detected: 73\n",
      "Face detected: 74\n",
      "Face detected: 75\n",
      "Face detected: 76\n",
      "Face detected: 77\n",
      "Face detected: 78\n",
      "Face detected: 79\n",
      "Face detected: 80\n",
      "Face detected: 81\n",
      "Face detected: 82\n",
      "Face detected: 83\n",
      "face not found\n",
      "Face detected: 84\n",
      "Face detected: 85\n",
      "Face detected: 86\n",
      "Face detected: 87\n",
      "Face detected: 88\n",
      "Face detected: 89\n",
      "Face detected: 90\n",
      "Face detected: 91\n",
      "Face detected: 92\n",
      "Face detected: 93\n",
      "Face detected: 94\n",
      "Face detected: 95\n",
      "Face detected: 96\n",
      "Face detected: 97\n",
      "Face detected: 98\n",
      "Face detected: 99\n",
      "Face detected: 100\n",
      "Collecting samples complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Load Haarcascade Classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extracter(img):\n",
    "    #Function detects faces and returns the cropped images\n",
    "    #If no faces detected , it returns Input Image\n",
    "    #gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    \n",
    "    #Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "#Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "#count 100 samples of your faces from webcam input\n",
    "\n",
    "while True:\n",
    "    return_value , frame = cap.read()\n",
    "    if face_extracter(frame) is not None:\n",
    "        count +=1\n",
    "        face = cv2.resize(cv2.cvtColor(face_extracter(frame),cv2.COLOR_BGR2GRAY),(400,400))\n",
    "        file_name_path = \"./faces/user/\" + str(count) + \".jpg\"\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        print(\"Face detected:\",count)\n",
    "        #Put count on images and display live count\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,0),2)\n",
    "        cv2.imshow(\"Face Dataset Collection\",face)\n",
    "    else:\n",
    "        print(\"face not found\")\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13 or count == 100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Collecting samples complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd5eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74df90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76a799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb83307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained Successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "data_path = \"./faces/user/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "#Create array for training data and labels\n",
    "Training_data , Labels = [],[]\n",
    "#Open Training images in our datapath\n",
    "#Create numpy array for training data\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    Training_data.append(np.asarray(image))\n",
    "    Labels.append(np.asarray(i))\n",
    "#Initialize Facial Recognization\n",
    "#model = cv2.face.createLBPHFaceRecognizer()\n",
    "#NOTE: For opencv 3.0 use cv2.face.createLBPHFaceRecognizer\n",
    "#pip install opencv-contrib-python\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\n",
    "model.train(np.asarray(Training_data),np.asarray(Labels))\n",
    "print(\"Model Trained Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "057369ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_detector(img,size=0.5):\n",
    "    #Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if len(faces) == 0:\n",
    "        return img,[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    return_value,frame = cap.read()\n",
    "    image,face = face_detector(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        if results[1]<500:\n",
    "            confidence = int(100*(1-(results[1]/400)))\n",
    "            display_string = str(confidence) + \"% confidence it is user\"\n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,150),2)\n",
    "        if confidence > 90:\n",
    "            cv2.putText(image,\"hello\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow(\"Face Reognization\",image)\n",
    "        else:\n",
    "            cv2.putText(img,\"Not Found\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),1)\n",
    "            cv2.imshow(\"face Recognization\",image)\n",
    "    except:\n",
    "        cv2.putText(image,\"No Face Found\",(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,\"Locked\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow(\"Face Recognization\",image)\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808d1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
